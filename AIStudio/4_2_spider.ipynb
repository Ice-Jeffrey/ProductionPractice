{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting BeautifulSoup4\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/66/25/ff030e2437265616a1e9b25ccc864e0371a0bc3adb7c5a404fd661c6f4f6/beautifulsoup4-4.9.1-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 9.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2 (from BeautifulSoup4)\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='mirrors.ustc.edu.cn', port=443): Read timed out. (read timeout=15)\")': /pypi/web/simple/soupsieve/\u001b[0m\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, BeautifulSoup4\n",
      "Successfully installed BeautifulSoup4-4.9.1 soupsieve-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, you need to use the persistence path as the following:\n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install BeautifulSoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/ba/39/0b5d76e64681243db516491bc449eff847d2708b465b60465b31ca13522e/lxml-4.5.1-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5MB 53.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.5.1\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting html5lib\n",
      "\u001b[?25l  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 9.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting webencodings (from html5lib)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.9 (from html5lib)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: webencodings, six, html5lib\n",
      "Successfully installed html5lib-1.1 six-1.15.0 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml -t /home/aistudio/external-libraries\n",
    "!pip install html5lib -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可:\r\n",
    "# Also add the following code, so that every time the environment (kernel) starts, just run the following code:\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "* atcoder是日本的编程竞赛平台，因为时差原因，比赛时间设置比codeforces更加友好\n",
    "* 北京化工大学acm队员们也在atcoder上参加了很多的比赛\n",
    "* atcoder并没有提供api数据接口，因此需要解析网页来爬取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 用户atcoder参赛记录网站打开截图\n",
    "### 网址：[https://atcoder.jp/users/Trebleb/history](https://atcoder.jp/users/Trebleb/history)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4aaa6c2c098347889059120383786208b6e7833f221d4f02bfad95d9d29a01ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2019-11-24 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 146', 'rank': '3233', 'newRating': '24', 'diff': '-'}, {'date': '2019-12-22 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 148', 'rank': '3851', 'newRating': '64', 'diff': '+40'}, {'date': '2020-01-10 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 150', 'rank': '2534', 'newRating': '-', 'diff': '-'}, {'date': '2020-01-18 23:00:00+0900', 'contest': 'Keyence Programming Contest 2020', 'rank': '1503', 'newRating': '226', 'diff': '+162'}, {'date': '2020-01-19 22:30:00+0900', 'contest': 'AtCoder Beginner Contest 152', 'rank': '3611', 'newRating': '258', 'diff': '+32'}, {'date': '2020-01-26 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 153', 'rank': '1824', 'newRating': '418', 'diff': '+160'}, {'date': '2020-02-16 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 155', 'rank': '4369', 'newRating': '411', 'diff': '-7'}, {'date': '2020-02-22 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 156', 'rank': '1375', 'newRating': '564', 'diff': '+153'}, {'date': '2020-03-01 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 157', 'rank': '2639', 'newRating': '596', 'diff': '+32'}, {'date': '2020-03-07 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 158', 'rank': '2650', 'newRating': '634', 'diff': '+38'}, {'date': '2020-03-14 22:40:00+0900', 'contest': 'Panasonic Programming Contest 2020', 'rank': '1416', 'newRating': '740', 'diff': '+106'}, {'date': '2020-03-22 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 159', 'rank': '3026', 'newRating': '760', 'diff': '+20'}, {'date': '2020-04-04 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 161', 'rank': '7039', 'newRating': '708', 'diff': '-52'}, {'date': '2020-04-12 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 162', 'rank': '4734', 'newRating': '708', 'diff': '±0'}, {'date': '2020-04-19 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 163', 'rank': '5051', 'newRating': '-', 'diff': '-'}, {'date': '2020-04-26 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 164', 'rank': '2861', 'newRating': '753', 'diff': '+45'}, {'date': '2020-05-02 22:50:00+0900', 'contest': 'AtCoder Beginner Contest 165', 'rank': '6898', 'newRating': '722', 'diff': '-31'}, {'date': '2020-05-10 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 167', 'rank': '6701', 'newRating': '698', 'diff': '-24'}, {'date': '2020-07-05 22:40:00+0900', 'contest': 'AtCoder Beginner Contest 173', 'rank': '3987', 'newRating': '715', 'diff': '+17'}]\n"
     ]
    }
   ],
   "source": [
    "# pip install BeautifulSoup4\n",
    "\n",
    "# 在开始导入相关库\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json, time\n",
    "\n",
    "# 自定义函数显示html网页文本\n",
    "def getUrlText(url):\n",
    "    while True:\n",
    "        try:\n",
    "            html = requests.get(url)\n",
    "            html = html.text\n",
    "            break\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print('ConnectionError -- please wait 3 seconds')\n",
    "            time.sleep(3)\n",
    "        except requests.exceptions.ChunkedEncodingError:\n",
    "            print('ChunkedEncodingError -- please wait 3 seconds')\n",
    "            time.sleep(3)    \n",
    "        except:\n",
    "            print('Unfortunitely -- An Unknow Error Happened, Please wait 3 seconds')\n",
    "            time.sleep(3)\n",
    "    return html\n",
    "\n",
    "# atcoder \n",
    "def getACUserData(acID):\n",
    "    url = \"https://atcoder.jp/users/\"+acID+\"/history\"\n",
    "    html = getUrlText(url)\n",
    "    # soup = BeautifulSoup(html, features=\"lxml\") # 使用lxml解析器进行解析，速度快\n",
    "    soup = BeautifulSoup(html, features=\"html5lib\") # 使用html5lib进行解析，容错性好，不依赖外部扩展\n",
    "    \n",
    "    # print(soup)\n",
    "\n",
    "    # 根据网页html结构，先找到html中id为history的元素\n",
    "    table = soup.select('#history')\n",
    "    if len(table) > 0:\n",
    "        t = table[0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "    # [dict1, dict2, ...]\n",
    "    # dict:{'date': date, 'contest': contest, 'rank': rank, 'newRating': newRanking, 'diff':diff}\n",
    "    data_list = []  \n",
    "\n",
    "    ''' enumerate函数用法:\n",
    "    enumerate是翻译过来是枚举的意思，看下它的方法原型：\n",
    "    enumerate(sequence, start=0)，返回一个枚举对象。sequence必须是序列或迭代器iterator，或者支持迭代的对象。\n",
    "    enumerate()返回对象的每个元素都是一个元组，每个元组包括两个值，一个是计数，一个是sequence的值，\n",
    "    计数是从start开始的，start默认为0。\n",
    "    '''\n",
    "\n",
    "    # 选择t中所有的tr元素进行提取\n",
    "    for idx, tr in enumerate(t.select('tr')): \n",
    "        if idx != 0:\n",
    "            tds = tr.select('td')\n",
    "            # 根据网页显示的字段进行提取\n",
    "            date = tds[0].select('time')[0].text\n",
    "            contest = tds[1].select('a')[0].text\n",
    "            rank = tds[2].select('a')[0].text\n",
    "            if len(tds[4].select('span')) > 0:\n",
    "                newRating = tds[4].select('span')[0].text\n",
    "            else:\n",
    "                newRating = tds[4].text\n",
    "            diff = tds[5].contents[0]\n",
    "            # print(date,contest,rank,newRating,diff)\n",
    "            data_list.append({\n",
    "                'date': date,\n",
    "                'contest': contest, \n",
    "                'rank': rank, \n",
    "                'newRating': newRating, \n",
    "                'diff':diff\n",
    "            })\n",
    "\n",
    "    return data_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    acID = \"Trebleb\" #\"a2018040538\"\n",
    "    dataList = getACUserData(acID)\n",
    "    print(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
